{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pwd","execution_count":19,"outputs":[{"output_type":"stream","text":"/kaggle/working\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --no-deps '../input/torchlibrosa/torchlibrosa-0.0.4-py3-none-any.whl' \n!pip install ../input/librosa1","execution_count":20,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: torchlibrosa==0.0.4 from file:///kaggle/input/torchlibrosa/torchlibrosa-0.0.4-py3-none-any.whl in /opt/conda/lib/python3.7/site-packages (0.0.4)\nProcessing /kaggle/input/librosa1\nRequirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from librosa==0.8.0) (2.1.8)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from librosa==0.8.0) (1.18.5)\nRequirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from librosa==0.8.0) (1.4.1)\nRequirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from librosa==0.8.0) (0.23.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.7/site-packages (from librosa==0.8.0) (0.14.1)\nRequirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from librosa==0.8.0) (4.4.2)\nRequirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from librosa==0.8.0) (0.2.2)\nRequirement already satisfied: numba>=0.43.0 in /opt/conda/lib/python3.7/site-packages (from librosa==0.8.0) (0.48.0)\nRequirement already satisfied: soundfile>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from librosa==0.8.0) (0.10.3.post1)\nRequirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.7/site-packages (from librosa==0.8.0) (1.1.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.0) (2.1.0)\nRequirement already satisfied: six>=1.3 in /opt/conda/lib/python3.7/site-packages (from resampy>=0.2.2->librosa==0.8.0) (1.14.0)\nRequirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /opt/conda/lib/python3.7/site-packages (from numba>=0.43.0->librosa==0.8.0) (0.31.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba>=0.43.0->librosa==0.8.0) (46.1.3.post20200325)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.7/site-packages (from soundfile>=0.9.0->librosa==0.8.0) (1.14.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pooch>=1.0->librosa==0.8.0) (20.1)\nRequirement already satisfied: appdirs in /opt/conda/lib/python3.7/site-packages (from pooch>=1.0->librosa==0.8.0) (1.4.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from pooch>=1.0->librosa==0.8.0) (2.23.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.8.0) (2.20)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->pooch>=1.0->librosa==0.8.0) (2.4.7)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa==0.8.0) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa==0.8.0) (1.24.3)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa==0.8.0) (2.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa==0.8.0) (2020.6.20)\nBuilding wheels for collected packages: librosa\n  Building wheel for librosa (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for librosa: filename=librosa-0.8.0-py3-none-any.whl size=201374 sha256=0b74e66703d30e0ae06f992650a80ad80622c904f000c4296786b1d390a68d8d\n  Stored in directory: /tmp/pip-ephem-wheel-cache-idfjoxt1/wheels/df/fc/c9/6650455770bd14d81771486dde26da9af25f0da4295d195271\nSuccessfully built librosa\nInstalling collected packages: librosa\n  Attempting uninstall: librosa\n    Found existing installation: librosa 0.8.0\n    Uninstalling librosa-0.8.0:\n      Successfully uninstalled librosa-0.8.0\nSuccessfully installed librosa-0.8.0\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#!pip install librosa\n#!pip install torchlibrosa\nimport sys\nfrom pathlib import Path\nsys.path.insert(0,\"../input/cnn14-sig\")\nprint(sys.path)\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport torch\nfrom fastprogress import progress_bar\nfrom dataset.mp3_dataset import INV_BIRD_CODE\nimport warnings\nfrom contextlib import contextmanager\nfrom typing import Optional\nimport logging\nimport time\nimport librosa\nfrom models.backbones import  Cnn14_16k\nfrom config.config_Cnn14_16k import model_config\nimport torch.nn.functional as F\n\nROOT = Path.cwd().parent\nprint(ROOT)\nRAW_DATA = ROOT / \"input/birdsong-recognition\"\nTEST_AUDIO_DIR = RAW_DATA / \"test_audio\"\nweights_path=ROOT/\"input/cnn14-sig/output/best-checkpoint-035epoch.tar\"\nSR = 32000\nif not TEST_AUDIO_DIR.exists():\n    TEST_AUDIO_DIR = ROOT/'input' / \"birdcall-check\" / \"test_audio\"\n    test = pd.read_csv(ROOT/'input'/ \"birdcall-check\" / \"test.csv\")\nelse:\n    test = pd.read_csv(RAW_DATA / \"test.csv\")","execution_count":21,"outputs":[{"output_type":"stream","text":"['../input/cnn14-sig', '../input/cnn14-sig', '..', '../input/cnn14-sig', '/kaggle/working', '/kaggle/lib/kagglegym', '/kaggle/lib', '/kaggle/input/birdsong-recognition', '/opt/conda/lib/python37.zip', '/opt/conda/lib/python3.7', '/opt/conda/lib/python3.7/lib-dynload', '', '/root/.local/lib/python3.7/site-packages', '/opt/conda/lib/python3.7/site-packages', '/src/bq-helper', '/opt/conda/lib/python3.7/site-packages/IPython/extensions', '/root/.ipython']\n/kaggle\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(config, weights_path):\n    model = Cnn14_16k(**config)\n    checkpoint = torch.load(weights_path)\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n    return model","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_clip(length,clip,period,stride,sr):\n    clips=[]\n    clip=clip[0:int(length*sr)].astype(np.float32)\n    start=0\n    while start<int(length*sr):\n        y=clip[start:start+period*sr]\n        if len(y)!=period*sr:\n            y_pad = np.zeros(period * sr, dtype=np.float32)\n            y_pad[0:len(y)] = y\n            clips.append(y_pad)\n            break\n        start=start+stride*sr\n        clips.append(y)\n    return clips \n","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rand_split_clip(rand_len,length,clip,period,stride,sr):\n    clips=[]\n    clip=clip[0:int(length*sr)].astype(np.float32)\n    start = np.random.randint(length*sr - rand_len*sr)\n    end=int(start+rand_len*sr)\n    while start<end:\n        y=clip[start:start+period*sr]\n        if len(y)!=period*sr:\n            y_pad = np.zeros(period * sr, dtype=np.float32)\n            y_pad[0:len(y)] = y\n            clips.append(y_pad)\n            break\n        start=start+stride*sr\n        clips.append(y)\n    return clips ","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prediction_for_clip(test_df, clip,model,threshold=0.5,period=5,stride=2,sr=32000,cut_length=30):\n    prediction_dict = {}\n    for i in range(test_df.shape[0]):\n        temp=test_df.loc[i, :]\n        row_id = temp.row_id\n        seconds=temp.seconds\n        if np.isnan(seconds) :\n            seconds=int(len(clip)/sr)\n        if seconds<=cut_length:\n            splited=split_clip(seconds, clip, period, stride, sr)\n        else:\n            splited=rand_split_clip(cut_length,seconds, clip, period, stride, sr)\n        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        all_events = set()\n        audio=torch.tensor(splited).to(device).float()\n        with torch.no_grad():\n            prediction = model(audio)[\"clipwise_output\"]\n            proba = prediction.detach().cpu().numpy()                  \n        labels = proba >= threshold\n        for label in labels:\n            label=np.argwhere(label).reshape(-1).tolist()\n            for i in label: \n                all_events.add(i)\n        if len(all_events) == 0:\n            prediction_dict[row_id] = \"nocall\"\n        else:\n            labels_str_list = list(map(lambda x: INV_BIRD_CODE[x], all_events))\n            label_string = \" \".join(labels_str_list)\n            prediction_dict[row_id] = label_string\n    return prediction_dict\n","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prediction(test_df,test_audio,model_config,target_sr,threshold,period,stride,weights_path,cut_length):\n    model = get_model(model_config,weights_path)\n    unique_audio_id = test_df.audio_id.unique()\n    warnings.filterwarnings(\"ignore\")\n    prediction_dfs = []\n    for audio_id in unique_audio_id:\n        clip, _ = librosa.load(test_audio / (audio_id + \".mp3\"),sr=target_sr,mono=True,res_type=\"kaiser_fast\")      \n        test_df_for_audio_id = test_df.query(f\"audio_id == '{audio_id}'\").reset_index(drop=True)\n        prediction_dict = prediction_for_clip(test_df_for_audio_id,clip,model,threshold,period,stride,target_sr,cut_length)\n        row_id = list(prediction_dict.keys())\n        birds = list(prediction_dict.values())\n        prediction_df = pd.DataFrame({\"row_id\": row_id,\"birds\": birds})\n        prediction_dfs.append(prediction_df)\n    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n    return prediction_df\n\n","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=prediction(test_df=test,\n                        test_audio=TEST_AUDIO_DIR,\n                        model_config=model_config,\n                        target_sr=SR,\n                        threshold=0.6,\n                        period=5,\n                        stride=5,\n                        weights_path=weights_path,\n                        cut_length=30\n                        )\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(submission)\n","execution_count":null,"outputs":[{"output_type":"stream","text":"5.0\n10.0\n15.0\n20.0\n25.0\n5.0\n10.0\n15.0\n20.0\n25.0\n30.0\n35.0\n5.0\n10.0\n15.0\n20.0\n25.0\n30.0\n35.0\n5.0\n10.0\n15.0\n20.0\n25.0\n30.0\n5.0\n10.0\n15.0\n20.0\n25.0\n30.0\n35.0\n5.0\n5.0\n10.0\n15.0\n20.0\n25.0\n30.0\n35.0\n40.0\n45.0\n5.0\n10.0\n15.0\n20.0\n25.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}